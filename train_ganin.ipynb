{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCbtyJtYhka_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/NASA_Transfer_Learning')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import data_loader\n",
    "from models.ganin import GaninModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhyykiwQgcjc"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "IMG_SIZE = 28\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1\n",
    "LR = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VRZRaQuHgWvW"
   },
   "outputs": [],
   "source": [
    "# MNIST\n",
    "transform_m = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "trainset_m = datasets.MNIST(\"./data/mnist\",\n",
    "                            train=True,\n",
    "                            download=False,\n",
    "                            transform=transform_m)\n",
    "trainloader_m = torch.utils.data.DataLoader(trainset_m,\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True)\n",
    "\n",
    "testset_m = datasets.MNIST(\"./data/mnist\",\n",
    "                           train=False,\n",
    "                           download=False,\n",
    "                           transform=transform_m)\n",
    "testloader_m = torch.utils.data.DataLoader(testset_m,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           shuffle=True)\n",
    "\n",
    "# MNIST-M\n",
    "transform_mm = transforms.Compose(\n",
    "    [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "DATA_DIR = \"data/mnist_m/processed/\"\n",
    "\n",
    "trainloader_mm = data_loader.fetch(\n",
    "    data_dir=os.path.join(DATA_DIR, 'mnist_m_train.pt'),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    transform=transform_mm,\n",
    ")\n",
    "\n",
    "testloader_mm = data_loader.fetch(\n",
    "    data_dir=os.path.join(DATA_DIR, 'mnist_m_test.pt'),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    transform=transform_mm,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = GaninModel().to(device)\n",
    "\n",
    "criterion_l = nn.CrossEntropyLoss()\n",
    "criterion_d = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "\n",
    "num_batches = min(len(trainloader_m), len(trainloader_mm)) # ~60000/batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1613538721811,
     "user": {
      "displayName": "Nishant Yadav",
      "photoUrl": "",
      "userId": "02529691709873630386"
     },
     "user_tz": 480
    },
    "id": "e5ho9dRaisl6",
    "outputId": "cd929eee-e2ae-4d48-b221-2ecd79649583"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "executionInfo": {
     "elapsed": 763,
     "status": "error",
     "timestamp": 1613538961224,
     "user": {
      "displayName": "Nishant Yadav",
      "photoUrl": "",
      "userId": "02529691709873630386"
     },
     "user_tz": 480
    },
    "id": "FirNI_6hjNHw",
    "outputId": "105ae6bf-c956-4444-f9bc-6ce93d843afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lamda: 0.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4dda8bd283ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mloss_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_d\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: function ReverseGradientLayerBackward returned an incorrect number of gradients (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "test_accuracy = []\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    running_loss_total = 0\n",
    "    running_loss_l = 0\n",
    "    running_loss_d = 0\n",
    "\n",
    "    dataiter_mm = iter(trainloader_mm)\n",
    "    dataiter_m = iter(trainloader_m)\n",
    "    lamda = (2 / (1 + np.exp(-10 * ((epoch + 0.0) / EPOCHS)))) - 1\n",
    "    print(f\"Lamda: {lamda}\")\n",
    "\n",
    "    net.train()\n",
    "    for batch in range(1, num_batches+1):\n",
    "        loss_total = 0\n",
    "        loss_d = 0\n",
    "        loss_l = 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        #for source domain\n",
    "        imgs, lbls = dataiter_m.next()\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "        imgs = torch.cat((imgs, imgs, imgs), 1)\n",
    "        out_l, out_d = net(imgs, lamda)  # lambda==lambda\n",
    "        loss_l = criterion_l(out_l, lbls)\n",
    "        actual_d = torch.zeros(out_d.shape)\n",
    "        actual_d = actual_d.to(device)\n",
    "        loss_d = criterion_d(out_d, actual_d)\n",
    "\n",
    "        #for target domain\n",
    "        imgs, lbls = dataiter_mm.next()\n",
    "        imgs = imgs.to(device)\n",
    "        _, out_d = net(imgs, lamda)\n",
    "        actual_d = torch.ones(out_d.shape)\n",
    "        actual_d = actual_d.to(device)\n",
    "        loss_d += criterion_d(out_d, actual_d)\n",
    "\n",
    "        loss_total = loss_d + loss_l\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        running_loss_total += loss_total\n",
    "        running_loss_d += loss_d\n",
    "        running_loss_l += loss_l\n",
    "\n",
    "        if batch % 300 == 0:\n",
    "          print(f\"Epoch: {epoch}/{EPOCHS} Batch: {batch}/{num_batches}\")\n",
    "          print(f\"Total Loss: {running_loss_total/batch}\")\n",
    "          print(f\"Label Loss: {running_loss_l/batch}\")\n",
    "          print(f\"Domain Loss: {running_loss_d/batch}\")\n",
    "\n",
    "\n",
    "    net.eval()\n",
    "    test_loss = 0 \n",
    "    accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "            net.eval()\n",
    "            for imgs, lbls in testloader_mm:\n",
    "                imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "                #print(logits.shape,lbls.shape)\n",
    "                logits, _ = net(imgs, lamda)\n",
    "                #print(logits.shape)\n",
    "                #print(lbls.shape)\n",
    "                #lbls = lbls.view(*logits.shape)\n",
    "                #print(logits.shape,lbls.shape)\n",
    "                test_loss += criterion_l(logits, lbls)\n",
    "\n",
    "                #logits to probabilities using softmax\n",
    "                ps = torch.exp(logits) / (torch.sum(torch.exp(logits)))\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                #print(top_p.shape, top_class.shape)\n",
    "                equals = top_class == lbls.view(*top_class.shape)\n",
    "                #print(top_class,lbls.view(*top_class.shape))\n",
    "                accuracy += torch.mean(equals.float())\n",
    "\n",
    "    test_accuracy.append(accuracy / len(testloader_mm))\n",
    "    print(f\"Test accuracy: {accuracy / len(testloader_mm)}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuZhcoiHGrPW"
   },
   "outputs": [],
   "source": [
    "# np.save('test_accuracy.npy', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 1985,
     "status": "ok",
     "timestamp": 1613538632857,
     "user": {
      "displayName": "Nishant Yadav",
      "photoUrl": "",
      "userId": "02529691709873630386"
     },
     "user_tz": 480
    },
    "id": "toJyq6WIKNcJ",
    "outputId": "c1304eb7-5d58-4a34-a0a5-fa46267f3f13"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(range(1,EPOCHS + 1),test_accuracy)\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Test Accuracy')\n",
    "\n",
    "# #plt.savefig('test_accuracy.pdf')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPNC7Hyr/wb+1eD1/7hsJzr",
   "collapsed_sections": [],
   "mount_file_id": "1oTijRN4SDrBuGrMiI6gPX7WlZ97ubGQC",
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
